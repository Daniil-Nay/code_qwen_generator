{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11816582,"sourceType":"datasetVersion","datasetId":7422010}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Установка зависимостей & импорт либр :)","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install pip3-autoremove\n!pip-autoremove torch torchvision torchaudio -y\n!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n!pip install unsloth\n!pip install git+https://github.com/evalplus/evalplus.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nfrom unsloth.chat_templates import get_chat_template, train_on_responses_only\nfrom datasets import load_dataset\nfrom transformers import TrainingArguments, DataCollatorForSeq2Seq\nfrom trl import SFTTrainer\nimport torch, json\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gpu_stats = torch.cuda.get_device_properties(0)\nstart_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\nmax_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n\nprint(f\"видеокарта = {gpu_stats.name}. VRAM= {max_memory} GB.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Константы","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = \"unsloth/Qwen3-0.6B-Base-bnb-4bit\" # или любая другая \nADAPTER_NAME = \"dxnay/qwen3-0.6b-lora-tuned\"  # hf\nBENCHMARK = \"openai_humaneval\"\nTRAIN_PATH = \"/kaggle/input/qwen-data/train.jsonl\"\nOUTPUT_BASE = \"samples_base.jsonl\"\nOUTPUT_TUNED = \"samples_tuned.jsonl\"\nMAX_NEW_TOKENS = 512\nMAX_SEQ_LENGTH = 2048\nSEED = 3407","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Инициализация модельки","metadata":{}},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=MODEL_NAME,\n    max_seq_length=MAX_SEQ_LENGTH,\n    dtype=None,\n    load_in_4bit=True,\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# конфигурация lora параметров","metadata":{}},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n    lora_alpha=16,\n    lora_dropout=0.07,\n    bias=\"none\",\n    use_gradient_checkpointing=\"unsloth\",\n    random_state=SEED,\n    use_rslora=False,\n    loftq_config=None,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## преобработка данных","metadata":{}},{"cell_type":"code","source":"tokenizer = get_chat_template(tokenizer, chat_template=\"qwen-2.5\")\n\ndef formatting_prompts_func(example):\n    text = tokenizer.apply_chat_template(\n        example[\"messages\"],\n        tokenize=False,\n        add_generation_prompt=False\n    )\n    return {\"text\": text}\n\ndataset = load_dataset(\"json\", data_files=TRAIN_PATH, split=\"train\")\ndataset = dataset.map(lambda x: {\"conversations\": x[\"messages\"]})\ndataset = dataset.map(formatting_prompts_func, batched=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# трейн модели ","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=2,\n    num_train_epochs=3,  \n    warmup_ratio=0.05,\n    learning_rate=2e-5,\n    max_grad_norm=0.9,\n    fp16=not torch.cuda.is_bf16_supported(),\n    bf16=torch.cuda.is_bf16_supported(),\n    logging_steps=1,\n    optim=\"paged_adamw_8bit\",\n    weight_decay=0.01,\n    lr_scheduler_type=\"cosine\", \n    seed=SEED,\n    output_dir=\"outputs\",\n    report_to=\"none\",\n)\n\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=MAX_SEQ_LENGTH,\n    data_collator=DataCollatorForSeq2Seq(tokenizer),\n    dataset_num_proc=4,\n    packing=False,\n    args=training_args,\n)\n\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part=\"<|im_start|>user\\n\",\n    response_part=\"<|im_start|>assistant\\n\"\n)\n\ntrainer_stats = trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Ушло времени на обучение: {trainer_stats.metrics['train_runtime']} секунд.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Сохранение tuned qwen","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(ADAPTER_NAME)\ntokenizer.save_pretrained(ADAPTER_NAME)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Функция для генерации на humaneval","metadata":{}},{"cell_type":"code","source":"def generate_samples(model, tokenizer, output_path: str, benchmark: str, benchmark_type: str):\n    tokenizer.pad_token_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n    model.eval()\n    dataset = load_dataset(benchmark, split=\"test\")\n\n    def extract_function(text):\n        lines = text.strip().split(\"\\n\")\n        try:\n            start = next(i for i, l in enumerate(lines) if l.strip().startswith(\"def \"))\n        except StopIteration:\n            return text\n        func = [lines[start]]\n        for l in lines[start+1:]:\n            if l.startswith(\" \") or l.startswith(\"\\t\") or not l.strip():\n                func.append(l)\n            else:\n                break\n        return \"\\n\".join(func)\n\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        for i, item in enumerate(tqdm(dataset)):\n            if benchmark_type == \"humaneval\":\n                task_id = f\"HumanEval/{i}\"\n                prompt = item[\"prompt\"]\n            elif benchmark_type == \"mbpp\":\n                task_id = f\"MBPP/{i}\"\n                prompt = item[\"text\"]\n            else:\n                raise ValueError(\"Неверный тип бенчмарка\")\n\n            inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n            with torch.no_grad():\n                output = model.generate(\n                    **inputs,\n                    max_new_tokens=MAX_NEW_TOKENS,\n                    do_sample=False\n                )\n\n            decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n            func_code = extract_function(decoded[len(prompt):])\n            f.write(json.dumps({\"task_id\": task_id, \"completion\": func_code}) + \"\\n\")\n\n    print(f\"Сэмплы сохранены в {output_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Оценка на HumanEval+MBPP (pretrained)","metadata":{}},{"cell_type":"code","source":"base_model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=MODEL_NAME,\n    max_seq_length=MAX_SEQ_LENGTH,\n    dtype=None,\n    load_in_4bit=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = get_chat_template(tokenizer, chat_template=\"qwen-2.5\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generate_samples(base_model, tokenizer, \"samples_base_humaneval.jsonl\", \"openai/openai_humaneval\", \"humaneval\")\n!evalplus.evaluate --dataset humaneval --samples samples_base_humaneval.jsonl\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generate_samples(base_model, tokenizer, \"samples_base_mbpp.jsonl\", \"Muennighoff/mbpp\", \"mbpp\")\n!evalplus.evaluate --dataset mbpp --samples samples_base_mbpp.jsonl\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Оценка на HumanEval+MBPP (tuned)","metadata":{}},{"cell_type":"code","source":"tuned_model, _ = FastLanguageModel.from_pretrained(\n    model_name=MODEL_NAME,\n    adapter_name=ADAPTER_NAME,\n    max_seq_length=MAX_SEQ_LENGTH,\n    dtype=None,\n    load_in_4bit=True,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generate_samples(tuned_model, tokenizer, \"samples_tuned_humaneval.jsonl\", \"openai/openai_humaneval\", \"humaneval\")\n!evalplus.evaluate --dataset humaneval --samples samples_tuned_humaneval.jsonl\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generate_samples(tuned_model, tokenizer, \"samples_tuned_mbpp.jsonl\", \"Muennighoff/mbpp\", \"mbpp\")\n!evalplus.evaluate --dataset mbpp --samples samples_tuned_mbpp.jsonl\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# для пуша на хаб ","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login, HfApi\ntoken = ''\nlogin(token=token)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.push_to_hub(ADAPTER_NAME, private=False)\ntokenizer.push_to_hub(ADAPTER_NAME, private=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}